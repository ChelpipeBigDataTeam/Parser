{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting BeautifulSoup4\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 2.2MB/s ta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: BeautifulSoup4\n",
      "Successfully installed BeautifulSoup4-4.6.0\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Downloading https://files.pythonhosted.org/packages/fe/71/640d6b3f911184bbd3b92b78478b770630f07d58f3c3bcd67d244bd616d1/lxml-4.2.2-cp36-cp36m-manylinux1_x86_64.whl (5.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.9MB 92kB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: lxml\n",
      "Successfully installed lxml-4.2.2\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import requests\n",
    "import lxml\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Объявлен конкурс на получение субсидий организациями легкой промышленности на возмещение затрат на обслуживание кредитов', 'url': 'http://frp74.ru/news/obyavlen-konkursnyy-otbor-dlya-organizatsiy-legkoy-promyshlennosti/', 'date': '25.04.2018'}\n",
      "{'name': 'Объявлен конкурсный отбор для организаций, реализующих инвестиционные проекты индустрии детских товаров', 'url': 'http://frp74.ru/news/obyavlen-konkursnyy-otbor-dlya-organizatsiy-realizuyushchikh-investitsionnye-proekty-industrii-detsk/', 'date': '13.04.2018'}\n",
      "{'name': 'Объявлен первый в 2018г. сбор предложений для формирования перечня технологических направлений в целях проведения конкурса для предоставления субсидий на НИОКР', 'url': 'http://frp74.ru/news/obyavlen-pervyy-v-2018g-sbor-predlozheniy-dlya-formirovaniya-perechnya-tekhnologicheskikh-napravleni/', 'date': '07.02.2018'}\n",
      "{'name': 'Объявлен конкурс на предоставление субсидии на компенсацию части затрат на реализацию пилотных партий промышленной продукции ', 'url': 'http://frp74.ru/news/obyavlen-konkurs-na-predostavlenie-subsidii-na-kompensatsiyu-chasti-zatrat-na-realizatsiyu-pilotnykh/', 'date': '07.12.2017'}\n"
     ]
    }
   ],
   "source": [
    "days = timedelta(300)\n",
    "deadline = datetime.now()-days\n",
    "    \n",
    "def get_html(url):\n",
    "    r = requests.get(url)\n",
    "    return r.text\n",
    " \n",
    "def get_total_pages(html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    divs = soup.find('div', class_='row pagination')\n",
    "    fonts = divs.find_all('font', class_='text')[1]\n",
    "    pages = fonts.find_all('a')[-1].get('href')\n",
    "    total_pages = pages.split('=')[1].split('&')[0]\n",
    "    return int(total_pages)\n",
    "\n",
    " \n",
    "def get_page_data(html):\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    news = soup.find_all('div', class_='column float-left small-3')\n",
    "    for new in news:\n",
    "        name = new.find('img').get('alt')\n",
    "        url = \"http://frp74.ru\" + new.find('a').get('href')\n",
    "        date_str = new.find('div', class_='date').getText()\n",
    "        date = datetime.strptime(date_str, '%d.%m.%Y')\n",
    "        \n",
    "        if date > deadline:\n",
    "#             print(date, deadline)\n",
    "            if \"конкурс\" in name.lower():\n",
    "                data = {'name':name,\n",
    "                        'url':url,\n",
    "                        'date':date_str}\n",
    "                print(data)\n",
    "        else:\n",
    "            return False\n",
    "    return True\n",
    " \n",
    " \n",
    "def main():\n",
    "    base_url = \"http://frp74.ru/news/\"\n",
    "    page_part = \"?PAGEN_1=\"\n",
    " \n",
    "    \n",
    "    total_pages = get_total_pages(get_html(base_url))\n",
    "    fl = True\n",
    "    for i in range(1, total_pages):\n",
    "        url_gen = base_url + page_part + str(i)\n",
    "        html = get_html(url_gen)\n",
    "        fl = get_page_data(html)\n",
    "        if fl==False:\n",
    "            break\n",
    "#         print(i)\n",
    "\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
